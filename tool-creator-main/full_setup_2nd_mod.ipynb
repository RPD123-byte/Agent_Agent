{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import instructor\n",
    "from getpass import getpass\n",
    "from openai import Client\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(api_key=\"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\")\n",
    "openai.api_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from numpy_serializer import numpy_json_serializer\n",
    "\n",
    "def chat_loop_single_interaction(client, thread_id, assistant_id, functions):\n",
    "    user_message = input(\"You: \")\n",
    "\n",
    "    # Add user message to thread\n",
    "    client.beta.threads.messages.create(\n",
    "        thread_id=thread_id,\n",
    "        role=\"user\",\n",
    "        content=user_message,\n",
    "    )\n",
    "\n",
    "\n",
    "    # Get assistant response in thread\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread_id,\n",
    "        assistant_id=assistant_id,\n",
    "    )\n",
    "\n",
    "    # Wait for the run to complete\n",
    "    while True:\n",
    "        run_status = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread_id,\n",
    "            run_id=run.id,\n",
    "        )\n",
    "\n",
    "        if run_status.status == \"completed\":\n",
    "            break\n",
    "        elif run_status.status == \"requires_action\":\n",
    "            handle_requires_action(run_status, functions, client, thread_id)\n",
    "        time.sleep(1)  # Adjust the sleep time as needed\n",
    "\n",
    "    # Retrieve the latest message from the thread (assistant's response)\n",
    "    latest_message = client.beta.threads.messages.list(\n",
    "        thread_id=thread_id,\n",
    "        limit=1,\n",
    "        order='desc'\n",
    "    ).data[0]\n",
    "\n",
    "    # Extract and return the assistant's response\n",
    "    assistant_response = extract_assistant_response(latest_message)\n",
    "    return assistant_response\n",
    "\n",
    "# Function definitions for 'handle_requires_action' and 'extract_assistant_response' remain the same\n",
    "\n",
    "\n",
    "def handle_requires_action(run_status, functions, client, thread_id):\n",
    "    tool_calls = run_status.required_action.submit_tool_outputs.tool_calls\n",
    "    tool_outputs = []\n",
    "\n",
    "    for tc in tool_calls:\n",
    "        function_name = tc.function.name\n",
    "        function_args = json.loads(tc.function.arguments or {})\n",
    "        function_to_call = functions.get(function_name)\n",
    "\n",
    "        if function_to_call:\n",
    "            try:\n",
    "                function_response = function_to_call(**function_args)\n",
    "                tool_outputs.append({\n",
    "                    \"tool_call_id\": tc.id,\n",
    "                    \"output\": json.dumps(function_response, default=numpy_json_serializer),\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Exception in function {function_name}: {e}\")\n",
    "\n",
    "    client.beta.threads.runs.submit_tool_outputs(\n",
    "        thread_id=thread_id,\n",
    "        run_id=run_status.id,\n",
    "        tool_outputs=tool_outputs\n",
    "    )\n",
    "\n",
    "def extract_assistant_response(message):\n",
    "    assistant_response = ''\n",
    "    for content in message.content:\n",
    "        if content.type == 'text':\n",
    "            assistant_response += content.text.value\n",
    "        elif content.type == 'image_file':\n",
    "            assistant_response += f\"\\n![Image](image_url)\"  # Modify as needed\n",
    "    return assistant_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreatorConfig:\n",
    "    def __init__(self):\n",
    "        self.create_tool_function = \"\"\"\n",
    "def create_tool(tool_name=None, tool_description=None, tool_parameters=None, tool_code=None, tool_dependencies=None, required_action_by_user=None):\n",
    "    \\\"\\\"\\\"\n",
    "    returns a tool that can be used by other assistants\n",
    "    \\\"\\\"\\\"\n",
    "\n",
    "    # create the tool file\n",
    "    os.makedirs('tools', exist_ok=True)\n",
    "    with open(f'tools/{tool_name}.py', 'w') as f:\n",
    "        f.write(tool_code)\n",
    "\n",
    "    # create the tool details file\n",
    "    tool_details = {\n",
    "        'name': tool_name,\n",
    "        'description': tool_description,\n",
    "        'parameters': tool_parameters,\n",
    "        'dependencies': tool_dependencies or '',\n",
    "    }\n",
    "\n",
    "    with open(f'tools/{tool_name}.json', 'w') as f:\n",
    "        json.dump(tool_details, f, indent=4)\n",
    "\n",
    "    return_value = f'created tool at tools/{tool_name}.py with details tools/{tool_name}.json\\\\n\\\\n'\n",
    "    if required_action_by_user:\n",
    "        return_value += f'There is a required action by the user before the tool can be used: {required_action_by_user}'\n",
    "\n",
    "    return return_value\n",
    "        \"\"\"\n",
    "        self.files_for_assistant = []\n",
    "        self.instructions_for_assistant = \"You create tools to accomplish arbitrary tasks. Write and run code to implement the interface for these tools using the OpenAI API format. You do not have access to the tools you create. Instruct the user that to use the tool, they will have to create an assistant equipped with that tool, or consult with the AssistantCreationAssistant about the use of that tool in a new assistant. Note that if a tool's output is visual, save the output to a file instead of displaying it in the console.\"\n",
    "        self.example_tool = \"\"\"\n",
    "def new_tool_name(param1=None, param2='default_value'):\n",
    "    if not param1: \n",
    "        return None\n",
    "        \n",
    "    # does something with the parameters to get the result\n",
    "    intermediate_output = ...\n",
    "        \n",
    "    # get the tool output\n",
    "    tool_output = ...\n",
    "        \n",
    "    return tool_output\n",
    "        \"\"\"\n",
    "        self.assistant_details = self._build_assistant_details()\n",
    "\n",
    "    def _build_assistant_details(self):\n",
    "        return {\n",
    "            'build_params' : {\n",
    "                'model': \"gpt-3.5-turbo-1106\", \n",
    "                'name': \"Tool Creator\",\n",
    "                'description': \"Assistant to create tools for use in the OpenAI platform by other Assistants.\",\n",
    "                'instructions': self.instructions_for_assistant, \n",
    "                'tools': [\n",
    "                    {\n",
    "                        \"type\": \"function\", \n",
    "                        \"function\": {\n",
    "                            \"name\": \"create_tool\",\n",
    "                            \"description\": \"returns a tool that can be used by other assistants. specify the tool_name, tool_description, tool_parameters, and tool_code. all of those are required. use the JSON schema for all tool_parameters.\",\n",
    "                            \"parameters\": {\n",
    "                                \"type\": \"object\",\n",
    "                                \"properties\": {\n",
    "                                    \"tool_name\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": \"The name of the tool, using snake_case e.g. new_tool_name\",\n",
    "                                    },\n",
    "                                    \"tool_description\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": \"The description of the tool, e.g. This tool does a computation using param1 and param2 to return a result that ...\",\n",
    "                                    },\n",
    "                                    \"tool_parameters\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": 'The parameters of the tool, using JSON schema to specify the type and properties for each parameter.\\n\\ne.g.\\n\\n{\"type\": \"object\", \"properties\": {\"location\": {\"type\": \"string\", \"description\": \"The city and state e.g. San Francisco, CA\"}, \"unit\": {\"type\": \"string\", \"enum\": [\"c\", \"f\"]}}, \"required\": [\"location\"]}',\n",
    "                                    },\n",
    "                                    \"tool_code\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": f\"The code for the tool, e.g. \\n{self.example_tool}\",\n",
    "                                    },\n",
    "                                    \"tool_dependencies\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": \"Optional. The dependencies for the tool, e.g. 'pandas\\nmatplotlib'. If there are no dependencies, do not include this parameter.\",\n",
    "                                    },\n",
    "                                    \"required_action_by_user\": {\n",
    "                                        \"type\": \"string\",\n",
    "                                        \"description\": \"Optional. The action required by the user before the tool can be used, e.g. 'set up API keys for service X and add them as environment variables' or 'install the module Y using pip'. It's important to be as detailed as possible so that these tools can be used for arbitrary tasks. If there is nothing required, do not include this parameter.\",\n",
    "                                    },\n",
    "                                },\n",
    "                                \"required\": [\"tool_name\", \"tool_description\", \"tool_parameters\", \"tool_code\"],\n",
    "                            },\n",
    "                        },\n",
    "                    },\n",
    "                ],\n",
    "                'file_ids': [],\n",
    "                'metadata': {},\n",
    "            },\n",
    "            'file_paths': self.files_for_assistant,\n",
    "            'functions': {\n",
    "                'create_tool': self.create_tool_function,\n",
    "            },\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create a tool-creator assistant using the assistant creation API\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "from jsonschema import Draft7Validator\n",
    "import jsonschema\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "def create_tool_creator(assistant_details):\n",
    "    # create the assistant\n",
    "    tool_creator = client.beta.assistants.create(**assistant_details[\"build_params\"])\n",
    "\n",
    "    print(f\"Created assistant to create tools: {tool_creator.id}\\n\\n\" + 90*\"-\" + \"\\n\\n\", flush=True)\n",
    "\n",
    "    # save the assistant info to a json file\n",
    "    info_to_export = {\n",
    "        \"assistant_id\": tool_creator.id,\n",
    "        \"assistant_details\": assistant_details,\n",
    "    }\n",
    "\n",
    "    os.makedirs('assistants', exist_ok=True)\n",
    "    with open('assistants/tool_creator.json', 'w') as f:\n",
    "        json.dump(info_to_export, f, indent=4)\n",
    "\n",
    "    return tool_creator\n",
    "\n",
    "def talk_to_tool_creator(assistant_details):\n",
    "    \"\"\"\n",
    "    talk to the assistant to create tools\n",
    "    \"\"\"\n",
    "\n",
    "    # check if json file exists\n",
    "    try:\n",
    "        os.makedirs('assistants', exist_ok=True)\n",
    "        with open('assistants/tool_creator.json') as f:\n",
    "            create_new = input(f'Assistant details found in tool_creator.json. Create a new assistant? [y/N]')\n",
    "            if create_new == 'y':\n",
    "                raise Exception(\"User wants a new assistant\")\n",
    "            assistant_from_json = json.load(f)\n",
    "            tool_creator = client.beta.assistants.retrieve(assistant_from_json['assistant_id'])\n",
    "            print(f\"Loaded assistant details from tool_creator.json\\n\\n\" + 90*\"-\" + \"\\n\\n\", flush=True)\n",
    "            print(f'Assistant {tool_creator.id}:\\n')\n",
    "            assistant_details = assistant_from_json[\"assistant_details\"]\n",
    "    except:\n",
    "        tool_creator = create_tool_creator(assistant_details)\n",
    "        \n",
    "    creator_config = CreatorConfig()\n",
    "    \n",
    "    # Execute the create_tool_function string to define the function\n",
    "    exec(creator_config.create_tool_function, globals())\n",
    "\n",
    "    # Assuming create_tool is the function name defined in the string\n",
    "    create_tool_func = globals()['create_tool']\n",
    "\n",
    "    thread = client.beta.threads.create()\n",
    "\n",
    "    # Assuming create_tool is the function name defined in the string\n",
    "    create_tool_func = globals()['create_tool']\n",
    "\n",
    "    # Update agents_and_threads dictionary\n",
    "    agents_and_threads = {\n",
    "        \"tool_creator\": {\n",
    "            \"agent\": tool_creator,\n",
    "            \"thread\": thread,\n",
    "            \"funcs\": {\"create_tool\": create_tool_func}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Pass the correct thread ID to the chat loop\n",
    "    chat_loop_single_interaction(client, thread.id, tool_creator.id, agents_and_threads[\"tool_creator\"][\"funcs\"])\n",
    "\n",
    "# def main():\n",
    "#     # create the tool creator assistant and chat to create your tools\n",
    "#     creator_details = CreatorConfig().assistant_details\n",
    "#     talk_to_tool_creator(creator_details)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "\n",
    "class tool_evaluator:\n",
    "    openai_schema_unique = {\n",
    "        \"name\": \"tool_evaluator\",\n",
    "        \"description\": \"Function to evaluate the functionality and usefulness of tools\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"tool_path\": {\"type\": \"string\", \"description\": \"File path of the tool to be evaluated\"},\n",
    "            },\n",
    "            \"required\": [\"tool_path\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def __init__(self, tool_path):\n",
    "        self.tool_path = tool_path\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            # Execute the tool's code\n",
    "            result = subprocess.run(\n",
    "                ['python', self.tool_path],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                check=True\n",
    "            )\n",
    "            output = result.stdout\n",
    "\n",
    "            # Evaluate the output\n",
    "            if self.is_output_useful(output):\n",
    "                return \"Tool executed successfully and is useful.\"\n",
    "            else:\n",
    "                return \"Tool executed but the output is not useful.\"\n",
    "\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            return f\"Error executing tool: {e.stderr}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class talk_to_tool_creator:\n",
    "    openai_schema_unique = {\n",
    "        \"name\": \"talk_to_tool_creator\",\n",
    "        \"description\": \"Function to communicate with the tool creator and create tools\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"assistant_details\": {\"type\": \"string\", \"description\": \"Details about the assistant for the tool creator\"},\n",
    "            },\n",
    "            \"required\": [\"assistant_details\"]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def __init__(self, assistant_details):\n",
    "        self.assistant_details = json.loads(assistant_details)\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            # check if json file exists\n",
    "            # try:\n",
    "            os.makedirs('assistants', exist_ok=True)\n",
    "            with open('assistants/tool_creator.json') as f:\n",
    "                # create_new = input(f'Assistant details found in tool_creator.json. Create a new assistant? [y/N]')\n",
    "                # if create_new == 'y':\n",
    "                #     raise Exception(\"User wants a new assistant\")\n",
    "                assistant_from_json = json.load(f)\n",
    "                tool_creator = client.beta.assistants.retrieve(assistant_from_json['assistant_id'])\n",
    "                print(f\"Loaded assistant details from tool_creator.json\\n\\n\" + 90*\"-\" + \"\\n\\n\", flush=True)\n",
    "                print(f'Assistant {tool_creator.id}:\\n')\n",
    "                assistant_details = assistant_from_json[\"assistant_details\"]\n",
    "            # except:\n",
    "            #     tool_creator = create_tool_creator(assistant_details)\n",
    "                \n",
    "            creator_config = CreatorConfig()\n",
    "            # Execute the create_tool_function string to define the function\n",
    "            exec(creator_config.create_tool_function, globals())\n",
    "\n",
    "            create_tool_func = globals()['create_tool']\n",
    "            thread = client.beta.threads.create()\n",
    "\n",
    "            # Update agents_and_threads dictionary\n",
    "            agents_and_threads = {\n",
    "                \"tool_creator\": {\n",
    "                    \"agent\": tool_creator,\n",
    "                    \"thread\": thread,\n",
    "                    \"funcs\": {\"create_tool\": create_tool_func}\n",
    "                }\n",
    "            }\n",
    "\n",
    "            # Call chat_loop_single_interaction with correct parameters\n",
    "            return chat_loop_single_interaction(client, thread.id, tool_creator.id, agents_and_threads[\"tool_creator\"][\"funcs\"])\n",
    "        \n",
    "        except Exception as e:\n",
    "            return str(e)  # Return error message if any\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import builtins\n",
    "\n",
    "def wprint(*args, width=70, **kwargs):\n",
    "    \"\"\"\n",
    "    Custom print function that wraps text to a specified width.\n",
    "\n",
    "    Args:\n",
    "    *args: Variable length argument list.\n",
    "    width (int): The maximum width of wrapped lines.\n",
    "    **kwargs: Arbitrary keyword arguments.\n",
    "    \"\"\"\n",
    "    wrapper = textwrap.TextWrapper(width=width)\n",
    "\n",
    "    # Process all arguments to make sure they are strings and wrap them\n",
    "    wrapped_args = [wrapper.fill(str(arg)) for arg in args]\n",
    "\n",
    "    # Call the built-in print function with the wrapped text\n",
    "    builtins.print(*wrapped_args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_completion(message, agent, funcs, thread):\n",
    "    \"\"\"\n",
    "    Executes a thread based on a provided message and retrieves the completion result.\n",
    "\n",
    "    This function submits a message to a specified thread, triggering the execution of an array of functions\n",
    "    defined within a func parameter. Each function in the array must implement a `run()` method that returns the outputs.\n",
    "\n",
    "    Parameters:\n",
    "    - message (str): The input message to be processed.\n",
    "    - agent (OpenAI Assistant): The agent instance that will process the message.\n",
    "    - funcs (list): A list of function objects, defined with the instructor library.\n",
    "    - thread (Thread): The OpenAI Assistants API thread responsible for managing the execution flow.\n",
    "\n",
    "    Returns:\n",
    "    - str: The completion output as a string, obtained from the agent following the execution of input message and functions.\n",
    "    \"\"\"\n",
    "\n",
    "    # create new message in the thread\n",
    "    message = client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=message\n",
    "    )\n",
    "\n",
    "    # run this thread\n",
    "    run = client.beta.threads.runs.create(\n",
    "      thread_id=thread.id,\n",
    "      assistant_id=agent.id,\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "      # wait until run completes\n",
    "      while run.status in ['queued', 'in_progress']:\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "          thread_id=thread.id,\n",
    "          run_id=run.id\n",
    "        )\n",
    "        time.sleep(1)\n",
    "\n",
    "      # function execution\n",
    "      if run.status == \"requires_action\":\n",
    "        tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "        tool_outputs = []\n",
    "        for tool_call in tool_calls:\n",
    "          wprint('\\033[31m' + str(tool_call.function), '\\033[0m')\n",
    "          # find the tool to be executed\n",
    "          func = next(iter([func for func in funcs if func.__name__ == tool_call.function.name]))\n",
    "\n",
    "          try:\n",
    "            # init tool\n",
    "            func = func(**eval(tool_call.function.arguments))\n",
    "            # get outputs from the tool\n",
    "            output = func.run()\n",
    "          except Exception as e:\n",
    "            output = \"Error: \" + str(e)\n",
    "\n",
    "          wprint(f\"\\033[33m{tool_call.function.name}: \", output, '\\033[0m')\n",
    "          tool_outputs.append({\"tool_call_id\": tool_call.id, \"output\": output})\n",
    "\n",
    "        # submit tool outputs\n",
    "        run = client.beta.threads.runs.submit_tool_outputs(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id,\n",
    "            tool_outputs=tool_outputs\n",
    "        )\n",
    "      # error\n",
    "      elif run.status == \"failed\":\n",
    "        raise Exception(\"Run Failed. Error: \", run.last_error)\n",
    "      # return assistant message\n",
    "      else:\n",
    "        messages = client.beta.threads.messages.list(\n",
    "          thread_id=thread.id\n",
    "        )\n",
    "        message = messages.data[0].content[0].text.value\n",
    "        return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import Field\n",
    "from instructor import OpenAISchema\n",
    "\n",
    "class ExecutePyFile(OpenAISchema):\n",
    "    \"\"\"Run existing python file from local disc.\"\"\"\n",
    "    file_name: str = Field(\n",
    "        ..., description=\"The path to the .py file to be executed.\"\n",
    "    )\n",
    "\n",
    "    def run(self):\n",
    "      \"\"\"Executes a Python script at the given file path and captures its output and errors.\"\"\"\n",
    "      try:\n",
    "          result = subprocess.run(\n",
    "              ['python3', self.file_name],\n",
    "              text=True,\n",
    "              capture_output=True,\n",
    "              check=True\n",
    "          )\n",
    "          return result.stdout\n",
    "      except subprocess.CalledProcessError as e:\n",
    "          return f\"An error occurred: {e.stderr}\"\n",
    "\n",
    "class File(OpenAISchema):\n",
    "    \"\"\"\n",
    "    Python file with an appropriate name, containing code that can be saved and executed locally at a later time. This environment has access to all standard Python packages and the internet.\n",
    "    \"\"\"\n",
    "    chain_of_thought: str = Field(...,\n",
    "        description=\"Think step by step to determine the correct actions that are needed to be taken in order to complete the task.\")\n",
    "    file_name: str = Field(\n",
    "        ..., description=\"The name of the file including the extension\"\n",
    "    )\n",
    "    body: str = Field(..., description=\"Correct contents of a file\")\n",
    "\n",
    "    def run(self):\n",
    "        with open(self.file_name, \"w\") as f:\n",
    "            f.write(self.body)\n",
    "\n",
    "        return \"File written to \" + self.file_name\n",
    "    \n",
    "class InstallPackage(OpenAISchema):\n",
    "    \"\"\"\n",
    "    Installs a Python package using pip.\n",
    "    \"\"\"\n",
    "    package_name: str = Field(\n",
    "        ..., description=\"The name of the Python package to install.\"\n",
    "    )\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Executes pip install for the specified package and captures its output and errors.\"\"\"\n",
    "        try:\n",
    "            result = subprocess.run(\n",
    "                [sys.executable, \"-m\", \"pip\", \"install\", self.package_name],\n",
    "                text=True,\n",
    "                capture_output=True,\n",
    "                check=True\n",
    "            )\n",
    "            return f\"Package {self.package_name} installed successfully.\"\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            return f\"An error occurred while installing {self.package_name}: {e.stderr}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "code_assistant_funcs = [File, ExecutePyFile, InstallPackage, talk_to_tool_creator]\n",
    "\n",
    "code_assistant = client.beta.assistants.create(\n",
    "  name='Code Assistant Agent',\n",
    "  instructions=\"As a top-tier programming AI, you are adept at creating accurate Python scripts. You will properly name files and craft precise Python code with the appropriate imports to fulfill the user's request. Ensure to execute the necessary code before responding to the user.\",\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  tools=[{\"type\": \"function\", \"function\": File.openai_schema},\n",
    "         {\"type\": \"function\", \"function\": ExecutePyFile.openai_schema},\n",
    "         {\"type\": \"function\", \"function\": InstallPackage.openai_schema},\n",
    "         {\"type\": \"function\", \"function\": talk_to_tool_creator.openai_schema_unique}\n",
    "         ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from enum import Enum\n",
    "from pydantic import PrivateAttr\n",
    "from typing import Literal\n",
    "\n",
    "agents_and_threads = {\n",
    "    \"code_assistant\": {\n",
    "        \"agent\": code_assistant,\n",
    "        \"thread\": None,\n",
    "        \"funcs\": code_assistant_funcs\n",
    "    }\n",
    "}\n",
    "\n",
    "class SendMessage(OpenAISchema):\n",
    "    \"\"\"Send messages to other specialized agents in this group chat.\"\"\"\n",
    "    recepient:Literal['code_assistant'] = Field(..., description=\"code_assistant is a world class programming AI capable of executing python code.\")\n",
    "    message: str = Field(...,\n",
    "        description=\"Specify the task required for the recipient agent to complete. Focus instead on clarifying what the task entails, rather than providing detailed instructions.\")\n",
    "\n",
    "    def run(self):\n",
    "      recepient = agents_and_threads[self.recepient]\n",
    "      # if there is no thread between user proxy and this agent, create one\n",
    "      if not recepient[\"thread\"]:\n",
    "        recepient[\"thread\"] = client.beta.threads.create()\n",
    "\n",
    "      message = get_completion(message=self.message, **recepient)\n",
    "\n",
    "      return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_proxy_tools = [SendMessage]\n",
    "\n",
    "user_proxy = client.beta.assistants.create(\n",
    "  name='User Proxy Agent',\n",
    "  instructions=\"\"\"As a user proxy agent, your responsibility is to streamline the dialogue between the user and specialized agents within this group chat.\n",
    "Your duty is to articulate user requests accurately to the relevant agents and maintain ongoing communication with them to guarantee the user's task is carried out to completion.\n",
    "Please do not respond to the user until the task is complete, an error has been reported by the relevant agent, you are unable to do something only the user can do like installing\n",
    "a package, or you are certain of your response.\"\"\",\n",
    "  model=\"gpt-3.5-turbo-1106\",\n",
    "  tools=[\n",
    "      {\"type\": \"function\", \"function\": SendMessage.openai_schema},\n",
    "  ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mUser Proxy Agent: It seems that there was an error while trying to summarize the text. I\n",
      "will investigate this further and get back to you with a solution.\n",
      "Thank you for your patience. \u001b[0m\n",
      "\u001b[31mFunction(arguments='{\"recepient\":\"code_assistant\",\"message\":\"Plea\n",
      "se summarize the text: \\'The quick brown fox jumps over the lazy\n",
      "dog\\'\"}', name='SendMessage') \u001b[0m\n",
      "\u001b[31mFunction(arguments='{\"chain_of_thought\":\"Summarize the text \\'The\n",
      "quick brown fox jumps over the lazy dog\\' in\n",
      "Python.\",\"file_name\":\"text_summary.py\",\"body\":\"text = \\'The quick\n",
      "brown fox jumps over the lazy dog\\'\\\\nsummary = \\' \\'.join(word for\n",
      "word in text.split()[:5]) + \\'...\\'\\\\nprint(summary)\"}', name='File') \u001b[0m\n",
      "\u001b[33mFile: File written to text_summary.py \u001b[0m\n",
      "\u001b[31mFunction(arguments='{\"file_name\":\"text_summary.py\"}',\n",
      "name='ExecutePyFile') \u001b[0m\n",
      "\u001b[33mExecutePyFile: The quick brown fox jumps... \u001b[0m\n",
      "\u001b[33mSendMessage: The summary of the text \"The quick brown fox jumps over the lazy dog\"\n",
      "is: \"The quick brown fox jumps...\" \u001b[0m\n",
      "\u001b[34mUser Proxy Agent: The text has been summarized successfully. The summary of the text\n",
      "\"The quick brown fox jumps over the lazy dog\" is: \"The quick brown fox\n",
      "jumps...\". Is there anything else you would like to do? \u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/rithvikprakki/Downloads/tool-creator-main/full_setup_2nd_mod.ipynb Cell 14\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rithvikprakki/Downloads/tool-creator-main/full_setup_2nd_mod.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rithvikprakki/Downloads/tool-creator-main/full_setup_2nd_mod.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m   user_message \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mUser: \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/rithvikprakki/Downloads/tool-creator-main/full_setup_2nd_mod.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m   message \u001b[39m=\u001b[39m get_completion(user_message, user_proxy, user_proxy_tools, thread)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/rithvikprakki/Downloads/tool-creator-main/full_setup_2nd_mod.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   wprint(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\033\u001b[39;00m\u001b[39m[34m\u001b[39m\u001b[39m{\u001b[39;00muser_proxy\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m\"\u001b[39m, message,\u001b[39m'\u001b[39m\u001b[39m\\033\u001b[39;00m\u001b[39m[0m\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/rithvikprakki/Downloads/tool-creator-main/full_setup_2nd_mod.ipynb Cell 14\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rithvikprakki/Downloads/tool-creator-main/full_setup_2nd_mod.ipynb#X13sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m \u001b[39mwhile\u001b[39;00m run\u001b[39m.\u001b[39mstatus \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mqueued\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39min_progress\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rithvikprakki/Downloads/tool-creator-main/full_setup_2nd_mod.ipynb#X13sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m   run \u001b[39m=\u001b[39m client\u001b[39m.\u001b[39mbeta\u001b[39m.\u001b[39mthreads\u001b[39m.\u001b[39mruns\u001b[39m.\u001b[39mretrieve(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rithvikprakki/Downloads/tool-creator-main/full_setup_2nd_mod.ipynb#X13sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     thread_id\u001b[39m=\u001b[39mthread\u001b[39m.\u001b[39mid,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rithvikprakki/Downloads/tool-creator-main/full_setup_2nd_mod.ipynb#X13sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m     run_id\u001b[39m=\u001b[39mrun\u001b[39m.\u001b[39mid\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rithvikprakki/Downloads/tool-creator-main/full_setup_2nd_mod.ipynb#X13sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m   )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/rithvikprakki/Downloads/tool-creator-main/full_setup_2nd_mod.ipynb#X13sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m   time\u001b[39m.\u001b[39msleep(\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rithvikprakki/Downloads/tool-creator-main/full_setup_2nd_mod.ipynb#X13sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# function execution\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/rithvikprakki/Downloads/tool-creator-main/full_setup_2nd_mod.ipynb#X13sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mif\u001b[39;00m run\u001b[39m.\u001b[39mstatus \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrequires_action\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "thread = client.beta.threads.create()\n",
    "while True:\n",
    "  user_message = input(\"User: \")\n",
    "\n",
    "  message = get_completion(user_message, user_proxy, user_proxy_tools, thread)\n",
    "\n",
    "  wprint(f\"\\033[34m{user_proxy.name}: \", message,'\\033[0m')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tool_creator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
