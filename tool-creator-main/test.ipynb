{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import json\n",
    "import textwrap\n",
    "import builtins\n",
    "import time\n",
    "from openai import OpenAI\n",
    "import inspect\n",
    "import importlib.util\n",
    "import ast\n",
    "import shutil\n",
    "import re\n",
    "from typing import List\n",
    "import instructor\n",
    "from openai import Client\n",
    "import sys\n",
    "from typing import Optional\n",
    "import subprocess\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function allows you to see what the assistant is doing in the backed as it's being done\n",
    "def wprint(*args, width=70, **kwargs):\n",
    "    wrapper = textwrap.TextWrapper(width=width)\n",
    "    wrapped_args = [wrapper.fill(str(arg)) for arg in args]\n",
    "    builtins.print(*wrapped_args, **kwargs)\n",
    "\n",
    "def is_input_string(input_value) -> bool:\n",
    "    return isinstance(input_value, str)\n",
    "\n",
    "# This function deals with all the communication with the Assistants API\n",
    "def get_completion(message, agent, funcs, thread, client):\n",
    "    # Create new message in the thread\n",
    "    message_response = client.beta.threads.messages.create(\n",
    "        thread_id=thread.id,\n",
    "        role=\"user\",\n",
    "        content=message\n",
    "    )\n",
    "\n",
    "    if is_input_string(agent):\n",
    "        assistant_id = agent\n",
    "    else:\n",
    "        assistant_id = agent.id\n",
    "    \n",
    "    # Run the thread\n",
    "    run = client.beta.threads.runs.create(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant_id,\n",
    "    )\n",
    "\n",
    "    while True:\n",
    "        # Wait until run completes\n",
    "        run = client.beta.threads.runs.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            run_id=run.id\n",
    "        )\n",
    "\n",
    "        if run.status in ['queued', 'in_progress']:\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "\n",
    "        if run.status == \"requires_action\":\n",
    "            tool_calls = run.required_action.submit_tool_outputs.tool_calls\n",
    "            tool_outputs = []\n",
    "            for tool_call in tool_calls:\n",
    "                print(f\"Debug: Calling function {tool_call.function.name}\", flush=True)\n",
    "\n",
    "                wprint(f'\\033[31mFunction: {tool_call.function.name}\\033[0m')\n",
    "                func = next((f for f in funcs if f.__name__ == tool_call.function.name), None)\n",
    "                if func:\n",
    "                    try:\n",
    "                        # Assuming arguments are parsed correctly\n",
    "                        func_instance = func(**eval(tool_call.function.arguments))  # Consider safer alternatives to eval\n",
    "                        output = func_instance.run()\n",
    "\n",
    "                        # Ensure output is a string\n",
    "                        if not isinstance(output, str):\n",
    "                            output = str(output)\n",
    "                    except Exception as e:\n",
    "                        output = f\"Error: {e}\"\n",
    "                else:\n",
    "                    output = \"Function not found\"\n",
    "                wprint(f\"\\033[33m{tool_call.function.name}: {output}\\033[0m\")\n",
    "                tool_outputs.append({\"tool_call_id\": tool_call.id, \"output\": output})\n",
    "\n",
    "            run = client.beta.threads.runs.submit_tool_outputs(\n",
    "                thread_id=thread.id,\n",
    "                run_id=run.id,\n",
    "                tool_outputs=tool_outputs\n",
    "            )\n",
    "        elif run.status == \"failed\":\n",
    "            raise Exception(f\"Run Failed. Error: {run.last_error}\")\n",
    "        else:\n",
    "            messages = client.beta.threads.messages.list(\n",
    "                thread_id=thread.id\n",
    "            )\n",
    "            latest_message = messages.data[0].content[0].text.value\n",
    "            return latest_message\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a tool that can be given to chatgpt to use.\n",
    "# This one specifically is for vetor search, but you can use this as a template to create your own tools.\n",
    "# You just need the openai_schema, the __init__ to serve as an entry point for openai to give inputs, and a run function with all the code that should be run\n",
    "\n",
    "class vector_search_tool:\n",
    "    openai_schema = {\n",
    "        \"name\": \"vector_search_tool\",\n",
    "        \"description\": \"Performs vector search on tool descriptions to find relevant tools based on a user query.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\"type\": \"string\", \"description\": \"User's search query.\"},\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def __init__(self, query):\n",
    "        self.query = query\n",
    "        self.tool_database_path = 'tool_database.json'\n",
    "\n",
    "    def run(self):\n",
    "        try:\n",
    "            # Load tools from JSON file\n",
    "            with open(self.tool_database_path, 'r') as file:\n",
    "                data = json.load(file)\n",
    "                tool_data = data.get(\"tools\", [])  # Extract the tools list\n",
    "\n",
    "            # Ensure tool_data is a list\n",
    "            if not isinstance(tool_data, list):\n",
    "                raise ValueError(\"JSON data is not in expected list format\")\n",
    "\n",
    "            # Extract descriptions\n",
    "            descriptions = [tool.get('description', '') for tool in tool_data]\n",
    "\n",
    "            # Vectorize descriptions\n",
    "            vectorizer = TfidfVectorizer()\n",
    "            vectors = vectorizer.fit_transform(descriptions)\n",
    "\n",
    "            # Vectorize query\n",
    "            query_vec = vectorizer.transform([self.query])\n",
    "\n",
    "            # Calculate cosine similarity\n",
    "            cosine_similarities = cosine_similarity(query_vec, vectors).flatten()\n",
    "\n",
    "            # Get top 5 relevant tools' code\n",
    "            top_indices = cosine_similarities.argsort()[-5:][::-1]\n",
    "            top_tool_codes = [tool_data[i]['code'] for i in top_indices]\n",
    "\n",
    "            return top_tool_codes\n",
    "\n",
    "        except Exception as e:\n",
    "            return {\"error\": f\"Error during search: {str(e)}\"}\n",
    "\n",
    "# # Example usage\n",
    "# search_tool = tool_searcher(query=\"sphere volume\")\n",
    "# results = search_tool.run()\n",
    "# print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code uses the tools you created previously and the get_completion function to run an assistant. \n",
    "\n",
    "client = openai.OpenAI(api_key=\"\")\n",
    "\n",
    "# Define any tools you want the assistant to use here\n",
    "tool_searcher_tools = [vector_search_tool]\n",
    "\n",
    "tool_searcher_agent = client.beta.assistants.create(\n",
    "    name='Tool Searcher Agent',\n",
    "    instructions=\"\"\"\n",
    "    Put your instructions for what you want the assistant to do here\n",
    "    \"\"\",\n",
    "    # Cheapest and fastest GPT model right now. \n",
    "    model=\"gpt-3.5-turbo-0125\",\n",
    "    # Formally give the assistant the tool here\n",
    "    tools=[{\"type\": \"function\", \"function\": vector_search_tool.openai_schema},\n",
    "           ]\n",
    ")\n",
    "\n",
    "# Create a new thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# Main loop for user interaction\n",
    "user_input = input(\"User: \")\n",
    "message = get_completion(user_input, tool_searcher_agent, tool_searcher_tools, thread, client)\n",
    "wprint(f\"\\033[34m{tool_searcher_agent.name}: {message}\\033[0m\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tool_creator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
